{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0b3147",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "$$\\begin{split}\\begin{aligned}\n",
    "h' =\n",
    "\\begin{cases}\n",
    "    0 & \\text{ 概率为 } p \\\\\n",
    "    \\frac{h}{1-p} & \\text{ 其他情况}\n",
    "\\end{cases}\n",
    "\\end{aligned}\\end{split}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359b344",
   "metadata": {},
   "source": [
    "## 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7d08e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:23:08.220397Z",
     "start_time": "2022-10-12T02:23:05.005108Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce7cdd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:31:04.607299Z",
     "start_time": "2022-10-12T02:31:04.600394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3628, 0.8062, 0.8302],\n",
       "         [0.7695, 0.5216, 0.4206]]),\n",
       " tensor([[ True, False,  True],\n",
       "         [ True, False, False]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 1., 1.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand 均匀分布， randn 正态分布；\n",
    "torch.rand((2, 3)), (torch.rand((2, 3)) > 0.5), (torch.rand((2, 3)) > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d44219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:32:17.814867Z",
     "start_time": "2022-10-12T02:32:17.810891Z"
    }
   },
   "outputs": [],
   "source": [
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    # 在本情况中，所有元素都被丢弃\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(X)\n",
    "    # 在本情况中，所有元素都被保留\n",
    "    if dropout == 0:\n",
    "        return X\n",
    "    mask = (torch.rand(X.shape) > dropout).float() # 看上面的测试\n",
    "    return mask * X / (1 - dropout) # 完成dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440f617f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:32:42.524696Z",
     "start_time": "2022-10-12T02:32:42.520931Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试dropout_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "181b01a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:37:31.179267Z",
     "start_time": "2022-10-12T02:37:31.157330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0., 10., 12., 14.],\n",
      "        [16.,  0.,  0., 22., 24., 26., 28.,  0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(16, dtype = torch.float32).reshape((2, 8))\n",
    "\n",
    "print(X)\n",
    "print(dropout_layer(X, 0.))\n",
    "print(dropout_layer(X, 0.5))\n",
    "print(dropout_layer(X, 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06adb2d",
   "metadata": {},
   "source": [
    "定义模型\n",
    "\n",
    "将暂退法应用于每个隐藏层的输出（在激活函数之后）， 并且可以为每一层分别设置暂退概率： 常见的技巧是在靠近输入层的地方设置较低的暂退概率。 下面的模型将第一个和第二个隐藏层的暂退概率分别设置为0.2和0.5， 并且暂退法只在训练期间有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout1, dropout2 = 0.2, 0.5\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training = True):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.training = is_training\n",
    "        self.lin1 = nn.Linear(num_inputs, num_hiddens1)  # 第一层，输入层之后那一层\n",
    "        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)# 第二层\n",
    "        self.lin3 = nn.Linear(num_hiddens2, num_outputs) # 第三层，输出层；\n",
    "        self.relu = nn.ReLU()                            # 第三层，输出层之后用激活函数；\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
